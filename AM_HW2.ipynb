{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d45710c",
   "metadata": {},
   "source": [
    "### Natural Language Processing - Homework 2\n",
    "\n",
    "Submitted by: Apurv Mittal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8283cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from urllib import request\n",
    "import matplotlib as plt\n",
    "import os\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "#from nltk.book import *\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5308fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore Warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a98c3fd",
   "metadata": {},
   "source": [
    "Reading text files from http://www.gutenberg.org/ebooks/bookshelf/215 based on grade levels.\n",
    "\n",
    "We will take grade 2 through grade 6 texts for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0991fc92",
   "metadata": {},
   "source": [
    "#### Reference to read text files: \n",
    "https://www.pythontutorial.net/python-basics/python-read-text-file/\n",
    "\n",
    "http://www.nltk.org/book/ch03.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d1aea0",
   "metadata": {},
   "source": [
    "#### Read Grade 2 Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bccaa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: ﻿The Project Gutenberg EBook of McGuffey 's Second...>\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.gutenberg.org/cache/epub/14668/pg14668.txt\"\n",
    "response = request.urlopen(url)\n",
    "grade2book = response.read().decode('utf8')\n",
    "tokens2 = word_tokenize(grade2book)\n",
    "text2 = nltk.Text(tokens2)\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3cd304",
   "metadata": {},
   "source": [
    "#### Read Grade 3 Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35653c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: ﻿The Project Gutenberg EBook of McGuffey 's Third...>\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.gutenberg.org/cache/epub/14766/pg14766.txt\"\n",
    "response = request.urlopen(url)\n",
    "grade3book = response.read().decode('utf8')\n",
    "tokens3 = word_tokenize(grade3book)\n",
    "text3 = nltk.Text(tokens3)\n",
    "print(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72541a0a",
   "metadata": {},
   "source": [
    "#### Read Grade 4 Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a45ac2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: ﻿The Project Gutenberg EBook of McGuffey 's Fourth...>\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.gutenberg.org/cache/epub/14880/pg14880.txt\"\n",
    "response = request.urlopen(url)\n",
    "grade4book = response.read().decode('utf8')\n",
    "tokens4 = word_tokenize(grade4book)\n",
    "text4 = nltk.Text(tokens4)\n",
    "print(text4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719be94c",
   "metadata": {},
   "source": [
    "#### Read Grade 5 Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a0f1a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: ﻿The Project Gutenberg EBook of McGuffey 's Fifth...>\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.gutenberg.org/cache/epub/15040/pg15040.txt\"\n",
    "response = request.urlopen(url)\n",
    "grade5book = response.read().decode('utf8')\n",
    "tokens5 = word_tokenize(grade5book)\n",
    "text5 = nltk.Text(tokens5)\n",
    "print(text5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d1ea21",
   "metadata": {},
   "source": [
    "#### Read Grade 6 Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1b06ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: ﻿The Project Gutenberg EBook of McGuffey 's Sixth...>\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.gutenberg.org/cache/epub/16751/pg16751.txt\"\n",
    "response = request.urlopen(url)\n",
    "grade6book = response.read().decode('utf8')\n",
    "tokens6 = word_tokenize(grade6book)\n",
    "text6 = nltk.Text(tokens6)\n",
    "print(text6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83f71b4",
   "metadata": {},
   "source": [
    "#### Method to get the Vocab Size and normalize the score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c46c4ab",
   "metadata": {},
   "source": [
    "##### Reference: Homework Example shared with the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "990158a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Method to get the Vocab Size and normalize the score\n",
    "\n",
    "def n_vocab_size(*arg):\n",
    "    vocab_size = np.array([])\n",
    "    vocab_size_norm = np.array([])\n",
    "    \n",
    "    #### Getting the Vocab Size\n",
    "    for text in arg:\n",
    "        vocab_size = np.append(vocab_size,len(set(text)))\n",
    "    \n",
    "    #### Normalizing using the formula \n",
    "    for vsize in vocab_size:\n",
    "        vocab_size_norm = np.append(vocab_size_norm,(vsize - vocab_size.min()) /\n",
    "                                                    (vocab_size.max() - vocab_size.min()))\n",
    "    \n",
    "    #### Normalizing using sklearn preprocessing \n",
    "    vocab_size_norm_sklearn = minmax_scale(vocab_size, feature_range=(0,1), axis=0)\n",
    "    \n",
    "    return(vocab_size,vocab_size_norm,vocab_size_norm_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52237a33",
   "metadata": {},
   "source": [
    "The above method is calculating the normalized score from an array of scores of different texts. There are two methods covered. `1` method is the manual calculation by using minimum vocabulary size of a text and comparing with maximum vocabulary size. `2` method is using an in-build function from sklearn. Its also doing the same calculations.\n",
    "\n",
    "For rest of this homework, we will be using SKlearn method for normalize calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9e21ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = n_vocab_size(text2,text3,text4,text5,text6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e5f972",
   "metadata": {},
   "source": [
    "Invoking the function to get the normalized vocabulary size from the function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd8900c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d1d7fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_vocab_list = vocab_size[2].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e560c109",
   "metadata": {},
   "source": [
    "Converting the tuple to a list for easy interpretation and calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6c98ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized vocabulary size for Grade 2 Book:  0.0\n",
      "Normalized vocabulary size for Grade 3 Book:  0.052202160610410164\n",
      "Normalized vocabulary size for Grade 4 Book:  0.48032031427060506\n",
      "Normalized vocabulary size for Grade 5 Book:  0.7757044647578756\n",
      "Normalized vocabulary size for Grade 6 Book:  0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalized vocabulary size for Grade 2 Book: \", norm_vocab_list[0])\n",
    "print(\"Normalized vocabulary size for Grade 3 Book: \", norm_vocab_list[1])\n",
    "print(\"Normalized vocabulary size for Grade 4 Book: \", norm_vocab_list[2])\n",
    "print(\"Normalized vocabulary size for Grade 5 Book: \", norm_vocab_list[3])\n",
    "print(\"Normalized vocabulary size for Grade 6 Book: \", norm_vocab_list[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b4c322",
   "metadata": {},
   "source": [
    "This is the normalized vocabulary size by the grades. As expected the normalized score is lowest for Grade 2 and its the highest for Grade 6. As the grades increase the text and vocabulary increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504fc46d",
   "metadata": {},
   "source": [
    "#### Long Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55829d5a",
   "metadata": {},
   "source": [
    "Now lets start with identifying the long words. For convenience and to avoid doing the same calculations multiple times, we have defined a function to identify the long words.\n",
    "\n",
    "For this exercise we have defined words longer than 10 to be long words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58be9ee",
   "metadata": {},
   "source": [
    "#### Reference for the function below: https://www.nltk.org/book/ch01.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8977412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def longwords(words):\n",
    "    v=set(words)\n",
    "    long = [w for w in v if len(v)>10]\n",
    "    return (long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c40504dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "long2 = longwords(text2)\n",
    "long3 = longwords(text3)\n",
    "long4 = longwords(text4)\n",
    "long5 = longwords(text5)\n",
    "long6 = longwords(text6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261afdac",
   "metadata": {},
   "source": [
    "Passing the gradewise text to the `longwords` function to get the list of long words. Now, we will pass these words to the normalized vocabulary score calculation function defined earlier to get the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57fe2beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = n_vocab_size(long2,long3,long4,long5,long6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3174557",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_long_vocab_list = vocab_size[2].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e849021",
   "metadata": {},
   "source": [
    "Converting from tuples to list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d08cb444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Long Words vocabulary size for Grade 2 Book:  0.0\n",
      "Normalized Long Words vocabulary size for Grade 3 Book:  0.052202160610410164\n",
      "Normalized Long Words vocabulary size for Grade 4 Book:  0.48032031427060506\n",
      "Normalized Long Words vocabulary size for Grade 5 Book:  0.7757044647578756\n",
      "Normalized Long Words vocabulary size for Grade 6 Book:  0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalized Long Words vocabulary size for Grade 2 Book: \", norm_long_vocab_list[0])\n",
    "print(\"Normalized Long Words vocabulary size for Grade 3 Book: \", norm_long_vocab_list[1])\n",
    "print(\"Normalized Long Words vocabulary size for Grade 4 Book: \", norm_long_vocab_list[2])\n",
    "print(\"Normalized Long Words vocabulary size for Grade 5 Book: \", norm_long_vocab_list[3])\n",
    "print(\"Normalized Long Words vocabulary size for Grade 6 Book: \", norm_long_vocab_list[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19545931",
   "metadata": {},
   "source": [
    "As expected the normalized score increses with grade level. Its lowest for Grade 2 and the highest for Grade 6 as many more longer words are added in grade 6 books compared to Grade 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe0f314",
   "metadata": {},
   "source": [
    "#### Text Difficulty Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808f9a7a",
   "metadata": {},
   "source": [
    "Defining a function to calculate Lexical Diversity with reference from the text book chapter 1.\n",
    "\n",
    "https://www.nltk.org/book/ch01.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "219dee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54a60b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical Diversity Score of Grade 2 Book:  0.1588342153068478\n",
      "Lexical Diversity Score of Grade 3 Book:  0.12404916695180691\n",
      "Lexical Diversity Score of Grade 4 Book:  0.12347441296124474\n",
      "Lexical Diversity Score of Grade 5 Book:  0.1128618252181811\n",
      "Lexical Diversity Score of Grade 6 Book:  0.10087260442906655\n"
     ]
    }
   ],
   "source": [
    "print(\"Lexical Diversity Score of Grade 2 Book: \",lexical_diversity(text2))\n",
    "print(\"Lexical Diversity Score of Grade 3 Book: \",lexical_diversity(text3))\n",
    "print(\"Lexical Diversity Score of Grade 4 Book: \",lexical_diversity(text4))\n",
    "print(\"Lexical Diversity Score of Grade 5 Book: \",lexical_diversity(text5))\n",
    "print(\"Lexical Diversity Score of Grade 6 Book: \",lexical_diversity(text6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab874583",
   "metadata": {},
   "source": [
    "The Lexical Diversity score is falling as we go higher in the grades. For example Grade 2 Lexical Diversity is 15.88% while that of Grade 6 book has reduced to 10.08%. This is surprising as one would expect the Lexical Diversity to be higher for higher grade books. The number of unique words should be lot more in the higher grade books, thus leading to higher Lexical Diversity. This needs to be analyzed further as its against our expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9e0264",
   "metadata": {},
   "source": [
    "To calculate `Text Difficulty Score`, we will take a mean of `Lexical Diversity Score`, `Normalized Vocabulary Score` and `Normalized Long Vocabulary Score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6cef3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_difficulty2 = (lexical_diversity(text2)+norm_long_vocab_list[0]+norm_vocab_list[0])/3\n",
    "text_difficulty3 = (lexical_diversity(text3)+norm_long_vocab_list[1]+norm_vocab_list[1])/3\n",
    "text_difficulty4 = (lexical_diversity(text4)+norm_long_vocab_list[2]+norm_vocab_list[2])/3\n",
    "text_difficulty5 = (lexical_diversity(text5)+norm_long_vocab_list[3]+norm_vocab_list[3])/3\n",
    "text_difficulty6 = (lexical_diversity(text6)+norm_long_vocab_list[4]+norm_vocab_list[4])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a7c6b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Difficulty Score of Grade 2 Book:  0.05294473843561593\n",
      "Text Difficulty Score of Grade 3 Book:  0.07615116272420908\n",
      "Text Difficulty Score of Grade 4 Book:  0.3613716805008183\n",
      "Text Difficulty Score of Grade 5 Book:  0.5547569182446441\n",
      "Text Difficulty Score of Grade 6 Book:  0.7002908681430221\n"
     ]
    }
   ],
   "source": [
    "print(\"Text Difficulty Score of Grade 2 Book: \",text_difficulty2)\n",
    "print(\"Text Difficulty Score of Grade 3 Book: \",text_difficulty3)\n",
    "print(\"Text Difficulty Score of Grade 4 Book: \",text_difficulty4)\n",
    "print(\"Text Difficulty Score of Grade 5 Book: \",text_difficulty5)\n",
    "print(\"Text Difficulty Score of Grade 6 Book: \",text_difficulty6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0d814d",
   "metadata": {},
   "source": [
    "Above, a `Text Difficutly Score` is printed for all grade books. As we expect the text difficulty increases with grades. Grade 2 sees the lowest `Text Difficutly Score` at `0.05` while it gradually increases by the grades and highest for Grade 6 at `0.70`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2350605d",
   "metadata": {},
   "source": [
    "#### - End of Homework 2 - "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
