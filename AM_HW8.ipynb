{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4548ed5",
   "metadata": {},
   "source": [
    "### Natural Language Processing - Homework 8\n",
    "\n",
    "Submitted by: Apurv Mittal\n",
    "\n",
    "Collaborated with Ravi Sivaraman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec73ab3",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2079d20c",
   "metadata": {},
   "source": [
    "First we fetch the reviews as covered in Homework # 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d74f71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "\n",
    "# Defining function to form the IMDB URL for movie reviews\n",
    "\n",
    "def get_review_permalink(movieid: str):\n",
    "    new_url = f'https://www.imdb.com/title/{movieid}/reviews?ref_=tt_urv'\n",
    "    imdb_data = urllib.request.urlopen(new_url).read().decode(\"UTF-8\")\n",
    "    soup = BeautifulSoup(imdb_data, \"html.parser\")\n",
    "    permalink = []\n",
    "    for link in soup.find_all('a'):\n",
    "        a_text = link.text.strip()\n",
    "        if a_text == \"Permalink\":\n",
    "            review_link = link.get('href')\n",
    "            review_link = \"https://imdb.com\" + review_link\n",
    "            permalink.append(review_link)\n",
    "    return permalink\n",
    "\n",
    "# Defining function to fetch the review from the URL\n",
    "\n",
    "def get_review(reviewurl: str):\n",
    "    review_data = urllib.request.urlopen(reviewurl).read().decode(\"UTF-8\")\n",
    "    soup = BeautifulSoup(review_data, \"html.parser\")\n",
    "    for eachdiv in soup.find_all('div'):\n",
    "        if eachdiv.has_attr('class'):\n",
    "            review_body_div_class = ['text', 'show-more__control']\n",
    "            review_body_div_class.sort()\n",
    "            divclass = eachdiv['class']\n",
    "            divclass.sort()\n",
    "            if review_body_div_class == divclass:\n",
    "                return (eachdiv.text.strip())\n",
    "\n",
    "# Reference: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "\n",
    "comedy_movies = ['tt0099088',\n",
    "                 'tt0099422',\n",
    "                 'tt0099611',\n",
    "                 'tt0099785',\n",
    "                 'tt0099938',\n",
    "                 'tt0100142',\n",
    "                 'tt0100405',\n",
    "                 'tt0100758',\n",
    "                 'tt0101272',\n",
    "                 'tt0101587',\n",
    "                 'tt0101786',\n",
    "                 'tt0101902',\n",
    "                 'tt0102032',\n",
    "                 'tt0102057',\n",
    "                 'tt0102059',\n",
    "                 'tt0102492',\n",
    "                 'tt0102510',\n",
    "                 'tt0102943',\n",
    "                 'tt0103060',\n",
    "                 'tt0103639',\n",
    "                 'tt0104070'\n",
    "                                \n",
    "                 ]\n",
    "\n",
    "# Chunking and printing the reviews\n",
    "\n",
    "permalinks_review = []\n",
    "counter = 1\n",
    "for each_movie in comedy_movies:\n",
    "    if counter >100:\n",
    "        break\n",
    "    permalinks = get_review_permalink(each_movie)\n",
    "    for review_url in permalinks:\n",
    "        review = get_review(review_url)\n",
    "        permalinks_review.append(review)\n",
    "        counter += 1\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f861d450",
   "metadata": {},
   "source": [
    "As covered in Homework 5, first we get the reviews from IMDB for comedy movies. We store all the reviews under one variable `permalinks_review`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16cf282",
   "metadata": {},
   "source": [
    "### Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f12161",
   "metadata": {},
   "source": [
    "We will use `vader lexicon` sentiment analyzer for this exercise.  To start with, first setup the sentiment analyzer. We install the required libraries. Add some `dummy` sentences to test the analyzer.\n",
    "\n",
    "Then print the sentiment scores for each sentences. It provides us with the `Negative`, `Neutral`, `Positive` weights of each sentence and based on the weights gives a `Compound` score. If the compound score is `Positive`, it means the overall sentiment is positive, whereas if the compund score is `Negative`, it means the overall sentiment is negative. The magnitude of the score tells us the magnitude of intensity of the particular sentiment.\n",
    "\n",
    "Reference code: https://realpython.com/python-nltk-sentiment-analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb58a4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most reviews are bad.\n",
      "compound: -0.5809, neg: 0.556, neu: 0.444, pos: 0.0, \n",
      "Some reviews are good.\n",
      "compound: 0.4404, neg: 0.0, neu: 0.508, pos: 0.492, \n",
      "If reviews are good, it means the movie is really good.\n",
      "compound: 0.7003, neg: 0.0, neu: 0.608, pos: 0.392, \n",
      "If reviews are bad then movie could be bad or good.\n",
      "compound: -0.6249, neg: 0.391, neu: 0.447, pos: 0.162, \n",
      "Better to watch movies with more good reviews.\n",
      "compound: 0.7264, neg: 0.0, neu: 0.496, pos: 0.504, \n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk import tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "dummy_sentences = [\n",
    "    \"Most reviews are bad.\",\n",
    "    \"Some reviews are good.\",\n",
    "    \"If reviews are good, it means the movie is really good.\",\n",
    "    \"If reviews are bad then movie could be bad or good.\",\n",
    "    \"Better to watch movies with more good reviews.\"\n",
    "    ]\n",
    "\n",
    "for sentence in dummy_sentences:\n",
    "    sentiment = SentimentIntensityAnalyzer()\n",
    "    print(sentence)\n",
    "    score = sentiment.polarity_scores(sentence)\n",
    "    for k in sorted(score):\n",
    "        print('{0}: {1}, '.format(k, score[k]), end='')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9133917f",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663bc3bd",
   "metadata": {},
   "source": [
    "For this question, we start with the work done in Homework 7. We take the clusters created using `k-Means` for `k=16`. A sample of clusters printed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f10cce77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               review  cluster\n",
      "99  A heavily dysfunctional family are going away ...        0\n",
      "96  Home Alone will stand the test of time, methin...        0\n",
      "86  This an absurd storyline. Hollywood loves to s...        0\n",
      "79  My response to this movie is strictly prejudic...        0\n",
      "50  Frankenhooker (1990) ** 1/2 (out of 4)More mad...        1\n",
      "..                                                ...      ...\n",
      "17  To come back for a sequel to a beloved film is...       14\n",
      "2   This movie continues from BTTF2. Marty McFly (...       14\n",
      "18  The final installment in the Back to the Futur...       14\n",
      "6   I thought this was a fun film, but for reasons...       14\n",
      "95  I like the bit when he slaps on aftershave and...       15\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(permalinks_review)\n",
    "\n",
    "\n",
    "k_val = 16\n",
    "kmeans = KMeans(n_clusters=k_val, init='k-means++', max_iter=200, n_init=10)\n",
    "kmeans.fit(X)\n",
    "labels=kmeans.labels_\n",
    "review_clustered_df=pd.DataFrame(list(zip(permalinks_review,labels)),columns=['review','cluster'])\n",
    "print(review_clustered_df.sort_values(by=['cluster']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960df49a",
   "metadata": {},
   "source": [
    "Now we pass the clusters identified through the `vader` sentiment analyzer from Question # 1. \n",
    "\n",
    "For each cluster we print the `average`, `median`, `high` and `low` sentiment score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc7f243e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster #  1\n",
      "Average: -0.04519466666666667 Median: 0.0 Low: -0.9442 High: 0.92\n",
      "Cluster #  2\n",
      "Average: 0.10699528795811518 Median: 0.0258 Low: -0.974 High: 0.9455\n",
      "Cluster #  3\n",
      "Average: 0.16936570512820512 Median: 0.2023 Low: -0.8604 High: 0.9974\n",
      "Cluster #  4\n",
      "Average: 0.3229175 Median: 0.45940000000000003 Low: -0.8271 High: 0.9912\n",
      "Cluster #  5\n",
      "Average: 0.20986315789473683 Median: 0.0 Low: -0.7845 High: 0.9834\n",
      "Cluster #  6\n",
      "Average: 0.2874 Median: 0.20885 Low: 0.0 High: 0.8479\n",
      "Cluster #  7\n",
      "Average: 0.11902321428571429 Median: 0.0 Low: -0.842 High: 0.9485\n",
      "Cluster #  8\n",
      "Average: -0.15586785714285714 Median: -0.0386 Low: -0.8977 High: 0.8705\n",
      "Cluster #  9\n",
      "Average: 0.14957777777777778 Median: 0.0 Low: -0.7003 High: 0.8304\n",
      "Cluster #  10\n",
      "Average: 0.323225 Median: 0.27115 Low: 0.0 High: 0.7506\n",
      "Cluster #  11\n",
      "Average: 0.2845179487179487 Median: 0.3071 Low: -0.9561 High: 0.9569\n",
      "Cluster #  12\n",
      "Average: 0.24975333333333333 Median: 0.2724 Low: -0.6467 High: 0.9712\n",
      "Cluster #  13\n",
      "Average: 0.55015 Median: 0.55015 Low: 0.4754 High: 0.6249\n",
      "Cluster #  14\n",
      "Average: 0.47619285714285714 Median: 0.57165 Low: -0.5267 High: 0.9747\n",
      "Cluster #  15\n",
      "Average: 0.23274598540145985 Median: 0.1531 Low: -0.8555 High: 0.9738\n",
      "Cluster #  16\n",
      "Average: 0.0772 Median: 0.0772 Low: 0.0772 High: 0.0772\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean, median\n",
    "\n",
    "for clusterid in range(k_val):\n",
    "\n",
    "    cluster_data_list = review_clustered_df.loc[review_clustered_df['cluster'] == clusterid ]['review'].tolist()\n",
    "    cluster_data = \"\".join(cluster_data_list)\n",
    "\n",
    "    sentiment = SentimentIntensityAnalyzer()\n",
    "    #score = sentiment.polarity_scores(cluster_data)\n",
    "    print(\"Cluster # \", clusterid+1)\n",
    "    #for k in sorted(score):\n",
    "        #print('{0}: {1}, '.format(k, score[k]), end='')\n",
    "    \n",
    "    scores = [\n",
    "        sentiment.polarity_scores(sentence)[\"compound\"]\n",
    "        for sentence in nltk.sent_tokenize(cluster_data)\n",
    "    ]\n",
    "    \n",
    "    print (\"Average:\",mean(scores),\"Median:\",median(scores), \"Low:\", min(scores), \"High:\",max(scores))\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9227ee01",
   "metadata": {},
   "source": [
    "Based on the scores printed above, we can see the average scores for most of the clusters in `positive`, however, for cluster `1` and cluster `8` the average score is negative. Even median score is negative for both of these clusters. This tells us that overall sentiment of these two cluster is `Negative`. \n",
    "\n",
    "Similarly, the average score for cluster `5`, `6`, `7`, `9`and `10` is positive; however the median score is `0`. Which tells the overall sentiment is more `neutral` than `positive`.\n",
    "\n",
    "Cluster `13` has the highest average positive score and also a very high median score.This cluster is definately most `positive` reviews.\n",
    "\n",
    "We can cross-check this analysis against the `vader` sentiment scores including `compound`, `positive` and `negative` scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a308dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster #  1\n",
      "compound: -0.9791, neg: 0.144, neu: 0.725, pos: 0.13, \n",
      "Cluster #  2\n",
      "compound: 0.9999, neg: 0.103, neu: 0.737, pos: 0.159, \n",
      "Cluster #  3\n",
      "compound: 1.0, neg: 0.095, neu: 0.722, pos: 0.183, \n",
      "Cluster #  4\n",
      "compound: 0.9999, neg: 0.059, neu: 0.741, pos: 0.2, \n",
      "Cluster #  5\n",
      "compound: 0.9996, neg: 0.099, neu: 0.718, pos: 0.183, \n",
      "Cluster #  6\n",
      "compound: 0.9432, neg: 0.04, neu: 0.81, pos: 0.15, \n",
      "Cluster #  7\n",
      "compound: 0.999, neg: 0.129, neu: 0.693, pos: 0.178, \n",
      "Cluster #  8\n",
      "compound: -0.9922, neg: 0.199, neu: 0.664, pos: 0.137, \n",
      "Cluster #  9\n",
      "compound: 0.9348, neg: 0.033, neu: 0.874, pos: 0.093, \n",
      "Cluster #  10\n",
      "compound: 0.8805, neg: 0.0, neu: 0.787, pos: 0.213, \n",
      "Cluster #  11\n",
      "compound: 0.9997, neg: 0.103, neu: 0.698, pos: 0.199, \n",
      "Cluster #  12\n",
      "compound: 0.9997, neg: 0.086, neu: 0.715, pos: 0.199, \n",
      "Cluster #  13\n",
      "compound: 0.8016, neg: 0.0, neu: 0.582, pos: 0.418, \n",
      "Cluster #  14\n",
      "compound: 0.9966, neg: 0.029, neu: 0.691, pos: 0.28, \n",
      "Cluster #  15\n",
      "compound: 0.9999, neg: 0.055, neu: 0.786, pos: 0.159, \n",
      "Cluster #  16\n",
      "compound: 0.0772, neg: 0.161, neu: 0.657, pos: 0.182, "
     ]
    }
   ],
   "source": [
    "for clusterid in range(k_val):\n",
    "\n",
    "    cluster_data_list = review_clustered_df.loc[review_clustered_df['cluster'] == clusterid ]['review'].tolist()\n",
    "    cluster_data = \"\".join(cluster_data_list)\n",
    "\n",
    "    sentiment = SentimentIntensityAnalyzer()\n",
    "    score = sentiment.polarity_scores(cluster_data)\n",
    "    print(\"\\nCluster # \", clusterid+1)\n",
    "    for k in sorted(score):\n",
    "        print('{0}: {1}, '.format(k, score[k]), end='')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf04cf56",
   "metadata": {},
   "source": [
    "The above scores confirm our analysis that Cluster `1` and `8` has negative sentiment and others have positive sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f217a95e",
   "metadata": {},
   "source": [
    "#### -End of Homework 8-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
